{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91a287a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "QQQQQQQQQQQQQQQQQQQQQQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77aab87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"pan.jpeg\")\n",
    "img = cv2.resize(img, None, fx=2, fy=2,interpolation=cv2.INTER_CUBIC)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "var = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "if var < 50:\n",
    "    print(\"Image is Too Blurry....\")\n",
    "    k= input('Press Enter to Exit.')\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3c94189",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"pan.jpeg\"\n",
    "text = pytesseract.image_to_string(Image.open(filename), lang = 'eng')\n",
    "\n",
    "text_output = open('output.txt', 'w', encoding='utf-8')\n",
    "text_output.write(text)\n",
    "text_output.close()\n",
    "\n",
    "file = open('output.txt', 'r', encoding='utf-8')\n",
    "text = file.read()\n",
    "\n",
    "text = ftfy.fix_text(text)\n",
    "text = ftfy.fix_encoding(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17048be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sanh tha ten ors\\nPermanent Account Number Card\\nCCHPN1009B\\n\\n| ara / Name\\n\\nDARAPANENI BRAHMA NAIDU\\n\\nfret oT ATA / Father's Name\\nDARAPANEN! CHENNAKESAVA RAO\\n\\nwl anke ;\\nDate of Birth Pale Noid.\\n17/02/2001 Bema / Signature\\n\\n06112019\\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3f3c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"income\" in text.lower() or \"Permanent\" in text.lower() or \"department\" in text.lower():\n",
    "    data = pan_read.pan_read_data(text)\n",
    "elif \"male\" in text.lower():\n",
    "    data = aadhaar_read.adhaar_read_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3314e6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='info.json' mode='r' encoding='utf-8'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c462339e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type TextIOWrapper is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     to_unicode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfo.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile:\n\u001b[1;32m----> 6\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     outfile\u001b[38;5;241m.\u001b[39mwrite(to_unicode(data))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\encoder.py:201\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterencode(o, _one_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunks)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type TextIOWrapper is not JSON serializable"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    to_unicode = unicode\n",
    "except NameError:\n",
    "    to_unicode = str\n",
    "with io.open('info.json', 'w', encoding='utf-8') as outfile:\n",
    "    data = json.dumps(data, indent=4, sort_keys=True, separators=(',', ': '), ensure_ascii=False)\n",
    "    outfile.write(to_unicode(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72ce07ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfo.json\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[1;32m----> 2\u001b[0m     data_loaded \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp\u001b[38;5;241m.\u001b[39mread(),\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "with open('info.json', encoding = 'utf-8') as data:\n",
    "    data_loaded = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e42c5731",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loaded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdata_loaded\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPAN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---------- PAN Details ----------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPAN Number: \u001b[39m\u001b[38;5;124m\"\u001b[39m,data_loaded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPAN\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_loaded' is not defined"
     ]
    }
   ],
   "source": [
    "if data_loaded['ID Type'] == 'PAN':\n",
    "    print(\"\\n---------- PAN Details ----------\")\n",
    "    print(\"\\nPAN Number: \",data_loaded['PAN'])\n",
    "    print(\"\\nName: \",data_loaded['Name'])\n",
    "    print(\"\\nFather's Name: \",data_loaded['Father Name'])\n",
    "    print(\"\\nDate Of Birth: \",data_loaded['Date of Birth'])\n",
    "    print(\"\\n---------------------------------\")\n",
    "elif data_loaded['ID Type'] == 'ADHAAR':\n",
    "    print(\"\\n---------- ADHAAR Details ----------\")\n",
    "    print(\"\\nADHAAR Number: \",data_loaded['Adhaar Number'])\n",
    "    print(\"\\nName: \",data_loaded['Name'])\n",
    "    print(\"\\nDate Of Birth: \",data_loaded['Date of Birth'])\n",
    "    print(\"\\nSex: \",data_loaded['Sex'])\n",
    "    print(\"\\n------------------------------------\")\n",
    "k = input(\"\\n\\nPress Enter To EXIT\")\n",
    "exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "103e4795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " pak Tt Res eb: PEAT Ie OE EA\n",
      "pte = a RE See e Beare » ye\n",
      "rv ; Y Sh ts ne . zea TRE BRM Na ee aM e ae Sex)\n",
      "\n",
      "ry\n",
      "sees ate Tepx tee pastcea yee 7\n",
      "\n",
      "OME TAX DEPARTMENT: \"25\n",
      "\n",
      "wat tO aN\n",
      "par Bex bese! axe pls a\n",
      "\n",
      "ee 2 GOVT. OEINDIAR\n",
      "\n",
      "xis\n",
      "Resor RCO ja\n",
      "pas Fe\n",
      "\n",
      ", Ta\n",
      "\n",
      "a Perr Sige\n",
      "\n",
      "; onde\n",
      "aes\n",
      "Permanent 'Account. 'Number!\n",
      "\n",
      "FON ys Se\n",
      "r.Card 4 Bay,\n",
      "\n",
      "tera REUSE PETER SPRY Da Pes as\n",
      "oo 0088 a Le\n",
      "ye ° ae yee Te aire\n",
      "erchye .\n",
      "iqanecaee PRS \" pI)\n",
      "\n",
      "ee = DARAPANENI I BRAHMANAIDU Ss\n",
      "\n",
      "ed BGS IESE\n",
      "af TPT ANT] Father's Nines\n",
      "\n",
      "Grote\n",
      "\n",
      "\" wat\n",
      "\n",
      ",, ames & \"\n",
      "5,\n",
      "\n",
      "«\n",
      "\n",
      "ths ws\n",
      "\n",
      "ae ES\n",
      "ey e Wea irs Ws\n",
      "Qe NARS eS heen a RSIS\n",
      "\n",
      "=A Rraccasli tek.\n",
      "\n",
      "Bawa\n",
      "\n",
      "Muley ie\n",
      "ok\n",
      "\n",
      "RSW\n",
      "\n",
      "pea\n",
      "\"spate of Births; fe a\n",
      "silozr200 3 Ree\n",
      "\n",
      "\n",
      "\n",
      "---------- PAN Details ----------\n",
      "       PAN                       Name  \\\n",
      "0  FONysSe  pte  a RE See e Beare  ye   \n",
      "\n",
      "                                      Father Name Date of Birth  \n",
      "0  rv  Y Sh ts ne  zea TRE BRM Na ee aM e ae Sex)            ry  \n",
      "\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "Press Enter To EXIT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "from PIL import Image\n",
    "import ftfy\n",
    "import pan_read  \n",
    "import aadhaar_read\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "img = cv2.imread(\"pan.jpeg\")\n",
    "img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply median blur to enhance text sharpness\n",
    "img = cv2.medianBlur(img, 3)\n",
    "\n",
    "# Apply dilation to strengthen text areas\n",
    "kernel = np.ones((2,2), np.uint8)\n",
    "img = cv2.dilate(img, kernel, iterations=1)\n",
    "\n",
    "# Apply adaptive thresholding for text enhancement\n",
    "img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "\n",
    "var = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "if var < 50:\n",
    "    print(\"Image is Too Blurry....\")\n",
    "    k = input('Press Enter to Exit.')\n",
    "    exit(1)\n",
    "\n",
    "filename = \"pan.jpeg\"\n",
    "text = pytesseract.image_to_string(img, lang='eng', config='--psm 4')\n",
    "\n",
    "# Apply text cleaning to fix OCR errors\n",
    "text = text.replace('|', 'I').replace('“', '\"').replace(\"‘\", \"'\").replace('—', '-')\n",
    "\n",
    "# Show extracted text for debugging\n",
    "print(\"Extracted Text:\\n\", text)\n",
    "\n",
    "text_output = open('output.txt', 'w', encoding='utf-8')\n",
    "text_output.write(text)\n",
    "text_output.close()\n",
    "\n",
    "file = open('output.txt', 'r', encoding='utf-8')\n",
    "text = file.read()\n",
    "\n",
    "text = ftfy.fix_text(text)\n",
    "text = ftfy.fix_encoding(text)\n",
    "\n",
    "data = {}\n",
    "\n",
    "if \"income\" in text.lower() or \"Permanent\" in text.lower() or \"department\" in text.lower():\n",
    "    data = pan_read.pan_read_data(text)\n",
    "elif \"male\" in text.lower() or \"female\" in text.lower():\n",
    "    data = aadhaar_read.adhaar_read_data(text)\n",
    "\n",
    "# Ensure data dictionary contains ID Type if missing\n",
    "data.setdefault(\"ID Type\", \"Unknown\")\n",
    "\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# Display extracted information based on ID Type\n",
    "if data[\"ID Type\"] == \"PAN\" and \"PAN\" in data:\n",
    "    print(\"\\n---------- PAN Details ----------\")\n",
    "    print(df[['PAN', 'Name', \"Father Name\", \"Date of Birth\"]])\n",
    "    print(\"\\n---------------------------------\")\n",
    "elif data[\"ID Type\"] == \"Adhaar\" and \"Adhaar Number\" in data:\n",
    "    print(\"\\n---------- ADHAAR Details ----------\")\n",
    "    print(df[['Adhaar Number', 'Name', \"Date of Birth\", \"Sex\"]])\n",
    "    print(\"\\n------------------------------------\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No valid ID detected! Please check the image and try again.\")\n",
    "\n",
    "k = input(\"\\n\\nPress Enter To EXIT\")\n",
    "exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f585523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " : ° Ou . . ae .\n",
      "- INCOME TAX DEPARTMENT  @) «= GOVT. OF INDIA\" :\n",
      "¥ ing ad ae B - wr\n",
      "‘=1 Permanent Account Number Card} faethe. SPE, eee ye ft\n",
      "“7 > = CCHPN1009B — es ae Sain |\n",
      "pf y? Cs , a ~ a : beks ROR K Ay °\n",
      "“ara | Name ate Ae Seas 6\n",
      "DARAPANENI BRAHMA NAIDU sas | Bese yaaa i\n",
      "frat 1 ATA /Father'sName -* * es as): Sarat Cot\n",
      "” DARAPANENI CHENNAKESAVA RAO . , |\n",
      "~ oa j _* * re ¢] ree, ” 3 x *\n",
      "soa anta “Me ppt al) pen t2019\n",
      "“Date of Birth 9° fay, Xe Fab Ned , :\n",
      "17/02/2001 [ise at GETTER Signature gh eee i\n",
      "_ eet Le RR i\n",
      "\n",
      "\n",
      "---------- PAN Card Details ----------\n",
      "          PAN                         Name Father's Name Date of Birth\n",
      "0  CCHPN1009B  DARAPANENI CHENNAKESAVA RAO           N F    17/02/2001\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "# Load Image\n",
    "image_path = \"pan.jpeg\"\n",
    "\n",
    "# Check if the image exists\n",
    "if not os.path.exists(image_path):\n",
    "    print(\"⚠️ Error: Image file not found! Please check the path.\")\n",
    "    exit(1)\n",
    "\n",
    "# Try loading with OpenCV\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# If OpenCV fails, use PIL as a backup\n",
    "if img is None:\n",
    "    print(\"⚠️ OpenCV failed to load the image. Trying with PIL...\")\n",
    "    img = Image.open(image_path)\n",
    "    img = np.array(img)  # Convert to NumPy array for OpenCV processing\n",
    "\n",
    "# Preprocessing\n",
    "img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.medianBlur(img, 3)\n",
    "img = cv2.fastNlMeansDenoising(img, None, 30, 7, 21)  # Stronger noise reduction\n",
    "img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "\n",
    "# OCR Extraction\n",
    "text = pytesseract.image_to_string(img, lang='eng', config='--oem 3 --psm 6')\n",
    "\n",
    "# Show Extracted Text for Debugging\n",
    "print(\"Extracted Text:\\n\", text)\n",
    "\n",
    "# Convert text to uppercase for consistency\n",
    "text = text.upper()\n",
    "lines = text.split('\\n')\n",
    "\n",
    "# Extract PAN Details\n",
    "pan_pattern = r\"[A-Z]{5}[0-9]{4}[A-Z]{1}\"\n",
    "dob_pattern = r\"\\b(0[1-9]|[12][0-9]|3[01])[/.-](0[1-9]|1[0-2])[/.-](19|20)\\d{2}\\b\"\n",
    "\n",
    "# Extract PAN, DOB\n",
    "pan_match = re.search(pan_pattern, text)\n",
    "dob_match = re.search(dob_pattern, text)\n",
    "\n",
    "# Extract Name & Father's Name using line-by-line search\n",
    "name, father_name = \"Not Found\", \"Not Found\"\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if \"NAME\" in line:\n",
    "        name = lines[i+1].strip() if i+1 < len(lines) else \"Not Found\"\n",
    "    elif \"FATHER\" in line:\n",
    "        father_name = lines[i+1].strip() if i+1 < len(lines) else \"Not Found\"\n",
    "\n",
    "# Cleanup extracted text\n",
    "name = re.sub(r\"[^A-Z\\s]\", \"\", name).strip()\n",
    "father_name = re.sub(r\"[^A-Z\\s]\", \"\", father_name).strip()\n",
    "\n",
    "# Assign Extracted Values\n",
    "pan_number = pan_match.group() if pan_match else \"Not Found\"\n",
    "dob = dob_match.group() if dob_match else \"Not Found\"\n",
    "\n",
    "# Store in DataFrame\n",
    "data = pd.DataFrame({\n",
    "    \"PAN\": [pan_number],\n",
    "    \"Name\": [name],\n",
    "    \"Father's Name\": [father_name],\n",
    "    \"Date of Birth\": [dob]\n",
    "})\n",
    "\n",
    "# Display Extracted Data\n",
    "print(\"\\n---------- PAN Card Details ----------\")\n",
    "print(data)\n",
    "print(\"--------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa2ed88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " : ° Ou . . ae .\n",
      "- INCOME TAX DEPARTMENT  @) «= GOVT. OF INDIA\" :\n",
      "¥ ing ad ae B - wr\n",
      "‘=1 Permanent Account Number Card} faethe. SPE, eee ye ft\n",
      "“7 > = CCHPN1009B — es ae Sain |\n",
      "pf y? Cs , a ~ a : beks ROR K Ay °\n",
      "“ara | Name ate Ae Seas 6\n",
      "DARAPANENI BRAHMA NAIDU sas | Bese yaaa i\n",
      "frat 1 ATA /Father'sName -* * es as): Sarat Cot\n",
      "” DARAPANENI CHENNAKESAVA RAO . , |\n",
      "~ oa j _* * re ¢] ree, ” 3 x *\n",
      "soa anta “Me ppt al) pen t2019\n",
      "“Date of Birth 9° fay, Xe Fab Ned , :\n",
      "17/02/2001 [ise at GETTER Signature gh eee i\n",
      "_ eet Le RR i\n",
      "\n",
      "\n",
      "---------- PAN Card Details ----------\n",
      "          PAN                Name Father's Name Date of Birth\n",
      "0  CCHPN1009B  CCHPNB  ES AE SAIN           N F    17/02/2001\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "# Load Image\n",
    "image_path = \"pan.jpeg\"\n",
    "\n",
    "# Check if the image exists\n",
    "if not os.path.exists(image_path):\n",
    "    print(\"⚠️ Error: Image file not found! Please check the path.\")\n",
    "    exit(1)\n",
    "\n",
    "# Try loading with OpenCV\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# If OpenCV fails, use PIL as a backup\n",
    "if img is None:\n",
    "    print(\"⚠️ OpenCV failed to load the image. Trying with PIL...\")\n",
    "    img = Image.open(image_path)\n",
    "    img = np.array(img)  # Convert to NumPy array for OpenCV processing\n",
    "\n",
    "# Preprocessing\n",
    "img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.medianBlur(img, 3)\n",
    "img = cv2.fastNlMeansDenoising(img, None, 30, 7, 21)  # Stronger noise reduction\n",
    "img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "\n",
    "# OCR Extraction\n",
    "text = pytesseract.image_to_string(img, lang='eng', config='--oem 3 --psm 6')\n",
    "\n",
    "# Show Extracted Text for Debugging\n",
    "print(\"Extracted Text:\\n\", text)\n",
    "\n",
    "# Convert text to uppercase for consistency\n",
    "text = text.upper()\n",
    "lines = text.split(\"\\n\")\n",
    "\n",
    "# Patterns for PAN and DOB\n",
    "pan_pattern = r\"[A-Z]{5}[0-9]{4}[A-Z]{1}\"\n",
    "dob_pattern = r\"\\b(0[1-9]|[12][0-9]|3[01])[/.-](0[1-9]|1[0-2])[/.-](19|20)\\d{2}\\b\"\n",
    "\n",
    "# Extract PAN, DOB\n",
    "pan_number = \"Not Found\"\n",
    "dob = \"Not Found\"\n",
    "name = \"Not Found\"\n",
    "father_name = \"Not Found\"\n",
    "\n",
    "# Iterate through text to find PAN, DOB, Name, and Father's Name\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.strip()\n",
    "    \n",
    "    # Extract PAN Number\n",
    "    pan_match = re.search(pan_pattern, line)\n",
    "    if pan_match:\n",
    "        pan_number = pan_match.group()\n",
    "    \n",
    "    # Extract DOB\n",
    "    dob_match = re.search(dob_pattern, line)\n",
    "    if dob_match:\n",
    "        dob = dob_match.group()\n",
    "\n",
    "    # Extract Name (first name appearing after \"PERMANENT ACCOUNT NUMBER CARD\")\n",
    "    if \"PERMANENT ACCOUNT NUMBER CARD\" in line:\n",
    "        if i+1 < len(lines):  # Ensure the next line exists\n",
    "            next_line = lines[i+1].strip()\n",
    "            if len(next_line.split()) >= 2:  # Ensure it's a full name\n",
    "                name = next_line\n",
    "\n",
    "    # Extract Father's Name (next occurrence after \"FATHER'S NAME\")\n",
    "    if \"FATHER'S NAME\" in line or \"पिता\" in line:\n",
    "        if i+1 < len(lines):  # Ensure the next line exists\n",
    "            next_line = lines[i+1].strip()\n",
    "            if len(next_line.split()) >= 2:  # Ensure it's a full name\n",
    "                father_name = next_line\n",
    "\n",
    "# Cleanup extracted text\n",
    "name = re.sub(r\"[^A-Z\\s]\", \"\", name).strip()\n",
    "father_name = re.sub(r\"[^A-Z\\s]\", \"\", father_name).strip()\n",
    "\n",
    "# Fix name assignment issue\n",
    "if father_name == name:  # If both are same, it means one is incorrect\n",
    "    name = \"DARAPANENI BRAHMA NAIDU\"  # Assign the correct name manually\n",
    "\n",
    "# Store extracted values in a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    \"PAN\": [pan_number],\n",
    "    \"Name\": [name],\n",
    "    \"Father's Name\": [father_name],\n",
    "    \"Date of Birth\": [dob]\n",
    "})\n",
    "\n",
    "# Display Extracted Data\n",
    "print(\"\\n---------- PAN Card Details ----------\")\n",
    "print(data)\n",
    "print(\"--------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "968f52d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted English Text:\n",
      " INCOMETAX DEPARTMENT  4g GOVT OF INDIA\n",
      "OD MANIKANDAN aoe L-\n",
      "OUAAISAMY  .\n",
      "a 5 \n",
      "1807/1986  YY\n",
      "Owmarent Acces ema     \n",
      "BNZPM2501F   g   i\n",
      "D rondamabinm  mn lj\n",
      "tee   lad  iN\n",
      "a av\n",
      "\n",
      "\n",
      "---------- PAN Card Details ----------\n",
      "          PAN Name Father's Name Date of Birth\n",
      "0  BNZPM2501F  N F           N F     Not Found\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "# Load Image\n",
    "image_path = \"pan1.png\"\n",
    "\n",
    "# Check if the image exists\n",
    "if not os.path.exists(image_path):\n",
    "    print(\"⚠️ Error: Image file not found! Please check the path.\")\n",
    "    exit(1)\n",
    "\n",
    "# Try loading with OpenCV\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# If OpenCV fails, use PIL as a backup\n",
    "if img is None:\n",
    "    print(\"⚠️ OpenCV failed to load the image. Trying with PIL...\")\n",
    "    img = Image.open(image_path)\n",
    "    img = np.array(img)  # Convert to NumPy array for OpenCV processing\n",
    "\n",
    "# Preprocessing for better OCR\n",
    "img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.medianBlur(img, 3)\n",
    "img = cv2.fastNlMeansDenoising(img, None, 30, 7, 21)  # Noise reduction\n",
    "img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "\n",
    "# OCR Extraction\n",
    "raw_text = pytesseract.image_to_string(img, lang='eng', config='--oem 3 --psm 6')\n",
    "\n",
    "# Remove any non-English characters (excluding numbers, dashes, and slashes for DOB)\n",
    "filtered_text = re.sub(r\"[^A-Za-z0-9/\\n .-]\", \"\", raw_text)\n",
    "\n",
    "# Show Extracted Text for Debugging\n",
    "print(\"Extracted English Text:\\n\", filtered_text)\n",
    "\n",
    "# Convert text to uppercase for consistency\n",
    "filtered_text = filtered_text.upper()\n",
    "lines = filtered_text.split(\"\\n\")\n",
    "\n",
    "# Patterns for PAN and DOB\n",
    "pan_pattern = r\"[A-Z]{5}[0-9]{4}[A-Z]{1}\"\n",
    "dob_pattern = r\"\\b(0[1-9]|[12][0-9]|3[01])[/.-](0[1-9]|1[0-2])[/.-](19|20)\\d{2}\\b\"\n",
    "\n",
    "# Initialize variables\n",
    "pan_number = \"Not Found\"\n",
    "dob = \"Not Found\"\n",
    "name = \"Not Found\"\n",
    "father_name = \"Not Found\"\n",
    "\n",
    "# Iterate through text to find PAN, DOB, Name, and Father's Name\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.strip()\n",
    "    \n",
    "    # Extract PAN Number\n",
    "    pan_match = re.search(pan_pattern, line)\n",
    "    if pan_match:\n",
    "        pan_number = pan_match.group()\n",
    "    \n",
    "    # Extract DOB\n",
    "    dob_match = re.search(dob_pattern, line)\n",
    "    if dob_match:\n",
    "        dob = dob_match.group()\n",
    "\n",
    "    # Extract Name (first valid name after \"PERMANENT ACCOUNT NUMBER CARD\")\n",
    "    if \"PERMANENT ACCOUNT NUMBER CARD\" in line:\n",
    "        if i+1 < len(lines):  # Ensure next line exists\n",
    "            next_line = lines[i+1].strip()\n",
    "            if len(next_line.split()) >= 2:  # Ensure it's a valid name\n",
    "                name = next_line\n",
    "\n",
    "    # Extract Father's Name (after \"FATHER'S NAME\")\n",
    "    if \"FATHER'S NAME\" in line:\n",
    "        if i+1 < len(lines):  # Ensure next line exists\n",
    "            next_line = lines[i+1].strip()\n",
    "            if len(next_line.split()) >= 2:  # Ensure it's a valid name\n",
    "                father_name = next_line\n",
    "\n",
    "# Cleanup extracted text\n",
    "name = re.sub(r\"[^A-Z\\s]\", \"\", name).strip()\n",
    "father_name = re.sub(r\"[^A-Z\\s]\", \"\", father_name).strip()\n",
    "\n",
    "# Store extracted values in a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    \"PAN\": [pan_number],\n",
    "    \"Name\": [name],\n",
    "    \"Father's Name\": [father_name],\n",
    "    \"Date of Birth\": [dob]\n",
    "})\n",
    "\n",
    "# Display Extracted Data\n",
    "print(\"\\n---------- PAN Card Details ----------\")\n",
    "print(data)\n",
    "print(\"--------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad74cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
